{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd00b88da433220d6372f7f1405438b428a7024b8d8be6881fc1d5b8a2f056aef66",
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "96160c183ff07d6c046f40bed1d80ae4c2bc02b8d35c4944e4b03a78efc4aa22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils import tensorboard\n",
    "import scipy.io as scio\n",
    "        \n",
    "from arena import Arena\n",
    "from env.env import Environment, SimplifiedEnvironment\n",
    "from agent.memory import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "source": [
    "## hyper-parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.0\n",
    "final_epsilon = 0.1\n",
    "hysteretic = 0.2\n",
    "final_hysteretic = 0.8\n",
    "anneal_period = 15000       \n",
    "episodes = 20000            \n",
    "episode_length = 100 \n",
    "# channel_fixed_period = [10, 5, 2, 1]\n",
    "reset_period = 10\n",
    "train_interval = 50\n",
    "num_agent = 8\n",
    "# num_packet = [1, 2, 3, 4, 5, 6] \n",
    "num_packet = [2, 4, 6] \n",
    "target_update_frequency = 4\n",
    "reward_weights = [0.03, 0.5, 1, 1]\n",
    "trace_length = 20\n",
    "batch_size = 32\n",
    "learning_rate=0.0001\n",
    "gamma=0.95\n",
    "memory_size = 1000      \n",
    "benchmark = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(2333)\n",
    "\n",
    "record_path = os.path.join('record', '{}_agents'.format(num_agent), benchmark, 'train')\n",
    "\n",
    "env = Environment(num_vehicle = num_agent, reward_weights = reward_weights, training=True)\n",
    "# env.channel_fixed_period = channel_fixed_period[0]\n",
    "\n",
    "memory = ReplayBuffer(num_agent = num_agent, episode_length = episode_length, obs_size=env.observation_space, capacity=memory_size)\n",
    "\n",
    "arena = Arena(env, memory, num_agent=env.num_vehicle, episode_length=episode_length, trace_length=trace_length, batch_size=batch_size, learning_rate=learning_rate, epsilon=epsilon, final_epsilon=final_epsilon, gamma=gamma, hysteretic=hysteretic, final_hysteretic=final_hysteretic, anneal_period=anneal_period, training=True, parameter_sharing=False, dueling=True, benchmark=benchmark)\n",
    "\n",
    "writer = tensorboard.SummaryWriter('./log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "reward_list = []\n",
    "v2i_rate_list = []\n",
    "v2v_success_list  = []\n",
    "v2i_rate_benchmark_list = []\n",
    "v2v_success_benchmark_list = []\n",
    "for episode in tqdm(range(episodes)):\n",
    "    if (episode + 1) % reset_period == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        # env.num_packet = np.random.choice(num_packet)\n",
    "        env.num_packet = 6\n",
    "        arena.reset()\n",
    "    loss = 0.\n",
    "    v2i_rate = 0.\n",
    "    v2v_success = 0.\n",
    "    v2i_rate_benchmark = 0.\n",
    "    v2v_success_benchmark = 0.\n",
    "    for step in range(episode_length):\n",
    "        with torch.no_grad():\n",
    "            arena.step()\n",
    "        if (step + 1) % train_interval == 0:\n",
    "            loss += arena.train() \n",
    "        v2i_rate += env.v2i_rate.sum()\n",
    "        v2v_success = max(v2v_success, np.sum(env.remaining_load <= 0))\n",
    "        v2i_rate_benchmark += env.v2i_rate_benchmark.sum()\n",
    "        v2v_success_benchmark = max(v2v_success_benchmark, np.sum(env.remaining_load_benchmark <= 0))\n",
    "\n",
    "    arena.update_eps_hys()\n",
    "    if (episode + 1) % target_update_frequency == 0:\n",
    "        arena.update_target_model()\n",
    "    \n",
    "    loss_list.append(loss)\n",
    "    reward_list.append(arena.episode_reward)\n",
    "    v2i_rate_list.append(v2i_rate / episode_length)\n",
    "    v2v_success_list.append(v2v_success / env.num_vehicle)\n",
    "    v2i_rate_benchmark_list.append(v2i_rate_benchmark / episode_length)\n",
    "    v2v_success_benchmark_list.append(v2v_success_benchmark / env.num_vehicle)\n",
    "\n",
    "    writer.add_scalar('loss', loss, episode)\n",
    "    writer.add_scalar('reward', arena.episode_reward, episode)\n",
    "    writer.add_scalar('v2i_rate', v2i_rate / episode_length, episode)\n",
    "    writer.add_scalar('v2v_success', v2v_success / env.num_vehicle, episode)\n",
    "    writer.add_scalar('v2i_rate_benchmark', v2i_rate_benchmark / episode_length, episode)\n",
    "    writer.add_scalar('v2v_success_benchmark', v2v_success_benchmark / env.num_vehicle, episode)\n",
    "# save models\n",
    "arena.save_models()\n",
    "# save data\n",
    "scio.savemat(os.path.join(record_path, 'loss_proposed_{}.mat'.format(benchmark)), \\\n",
    "    {'loss_proposed_{}'.format(benchmark) : loss_list})\n",
    "scio.savemat(os.path.join(record_path, 'reward_proposed_{}.mat'.format(benchmark)), \\\n",
    "    {'reward_proposed_{}'.format(benchmark) : reward_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2i_rate_proposed_{}.mat'.format(benchmark)), \\\n",
    "    {'v2i_rate_proposed_{}'.format(benchmark) : v2i_rate_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2v_success_proposed_{}.mat'.format(benchmark)), \\\n",
    "    {'v2v_success_proposed_{}'.format(benchmark) : v2v_success_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2i_rate_{}.mat'.format(benchmark)), \\\n",
    "    {'v2i_rate_{}'.format(benchmark) : v2i_rate_benchmark_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2v_success_{}.mat'.format(benchmark)), \\\n",
    "    {'v2v_success_{}'.format(benchmark) : v2v_success_benchmark_list})\n"
   ]
  },
  {
   "source": [
    "## evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmark = 'random'\n",
    "episode_len = 100\n",
    "episode = 20\n",
    "num_agent = 4\n",
    "num_seeds = 20\n",
    "num_packet_list = [1, 2, 3, 4, 5, 6]\n",
    "# num_packet_list = [5, 6]\n",
    "v2v_rate_list = [[] for _ in range(len(num_packet_list))]\n",
    "v2i_rate_list = [[] for _ in range(len(num_packet_list))]\n",
    "v2v_success_list = [[] for _ in range(len(num_packet_list))]\n",
    "v2v_rate_benchmark_list = [[] for _ in range(len(num_packet_list))]\n",
    "v2i_rate_benchmark_list = [[] for _ in range(len(num_packet_list))]\n",
    "v2v_success_benchmark_list = [[] for _ in range(len(num_packet_list))]\n",
    "\n",
    "record_path = os.path.join('record', '{}_agents'.format(num_agent), benchmark, 'evaluate')\n",
    "\n",
    "for i in tqdm(range(len(num_packet_list))):\n",
    "    num_packet = num_packet_list[i]\n",
    "\n",
    "    v2v_rate_mean = np.zeros(num_agent)\n",
    "    v2i_rate_mean = np.zeros(num_agent)\n",
    "    v2v_success_mean = 0.\n",
    "\n",
    "    v2v_rate_mean_benchmark = np.zeros(num_agent)\n",
    "    v2i_rate_mean_benchmark = np.zeros(num_agent)\n",
    "    v2v_success_mean_benchmark = 0.\n",
    "\n",
    "    for j in tqdm(range(num_seeds)):\n",
    "        setup_seed(1234 + 5 * j)\n",
    "        env = Environment(num_vehicle=num_agent, num_packet=num_packet, training=False)\n",
    "        memory = None\n",
    "        arena = Arena(env, memory, num_agent=env.num_vehicle, episode_length=episode_length, trace_length=trace_length, \\\n",
    "            batch_size=batch_size, training=False, parameter_sharing=False, dueling=True, benchmark=benchmark)\n",
    "\n",
    "        v2v_rate = np.zeros(num_agent)  \n",
    "        v2i_rate = np.zeros(num_agent)\n",
    "        v2v_success = 0.\n",
    "        v2v_rate_benchmark = np.zeros(num_agent)  \n",
    "        v2i_rate_benchmark = np.zeros(num_agent)\n",
    "        v2v_success_benchmark = 0.\n",
    "\n",
    "        for k in range(episode):\n",
    "            v2v_success_temp = 0.\n",
    "            v2v_success_temp_benchmark = 0.\n",
    "            for _ in range(episode_len):\n",
    "                arena.step()\n",
    "                v2v_rate += env.v2v_rate\n",
    "                v2i_rate += env.v2i_rate\n",
    "                v2v_success_temp = max(v2v_success_temp, np.sum(env.remaining_load <= 0))\n",
    "                v2v_rate_benchmark += env.v2v_rate_benchmark\n",
    "                v2i_rate_benchmark += env.v2i_rate_benchmark\n",
    "                v2v_success_temp_benchmark = max(v2v_success_temp_benchmark, \\\n",
    "                                                    np.sum(env.remaining_load_benchmark <= 0))\n",
    "\n",
    "            v2v_success += v2v_success_temp\n",
    "            v2v_success_benchmark += v2v_success_temp_benchmark\n",
    "            \n",
    "        v2v_rate /= (episode_len * episode)\n",
    "        v2i_rate /= (episode_len * episode)\n",
    "        v2v_success /= (episode * env.num_vehicle)\n",
    "        v2v_rate_benchmark /= (episode_len * episode)\n",
    "        v2i_rate_benchmark /= (episode_len * episode)\n",
    "        v2v_success_benchmark /= (episode * env.num_vehicle)\n",
    "\n",
    "        v2v_rate_mean += v2v_rate / num_seeds\n",
    "        v2i_rate_mean += v2i_rate / num_seeds\n",
    "        v2v_success_mean += v2v_success / num_seeds\n",
    "        v2v_rate_mean_benchmark += v2v_rate_benchmark / num_seeds\n",
    "        v2i_rate_mean_benchmark += v2i_rate_benchmark / num_seeds\n",
    "        v2v_success_mean_benchmark += v2v_success_benchmark / num_seeds\n",
    "\n",
    "        v2v_rate_list[i].append(v2v_rate.sum())\n",
    "        v2i_rate_list[i].append(v2i_rate.sum())\n",
    "        v2v_success_list[i].append(v2v_success * 100)\n",
    "        v2v_rate_benchmark_list[i].append(v2v_rate_benchmark.sum())\n",
    "        v2i_rate_benchmark_list[i].append(v2i_rate_benchmark.sum())\n",
    "        v2v_success_benchmark_list[i].append(v2v_success_benchmark * 100)\n",
    "    \n",
    "    print('Number of packets: {}'.format(num_packet))\n",
    "    print('My method----V2I Sum Rate: {:.2f}Mbps, V2V Sum Rate: {:.2f}Mbps, V2V Success Probability: {:.2f}%'.format(v2i_rate_mean.sum(), v2v_rate_mean.sum(), v2v_success_mean * 100))\n",
    "    print('Benchmark method----V2I Sum Rate: {:.2f}Mbps, V2V Sum Rate: {:.2f}Mbps, V2V Success Probability: {:.2f}%'.format(v2i_rate_mean_benchmark.sum(), v2v_rate_mean_benchmark.sum(), v2v_success_mean_benchmark * 100))\n",
    "\n",
    "# save data\n",
    "scio.savemat(os.path.join(record_path, 'v2v_rate_proposed_{}.mat'.format(benchmark)), \\\n",
    "    {'v2v_rate_proposed_{}'.format(benchmark) : v2v_rate_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2i_rate_proposed_{}.mat'.format(benchmark)), \\\n",
    "    {'v2i_rate_proposed_{}'.format(benchmark) : v2i_rate_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2v_success_proposed_{}.mat'.format(benchmark)), \\\n",
    "    {'v2v_success_proposed_{}'.format(benchmark) : v2v_success_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2v_rate_{}.mat'.format(benchmark)), \\\n",
    "    {'v2v_rate_{}'.format(benchmark) : v2v_rate_benchmark_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2i_rate_{}.mat'.format(benchmark)), \\\n",
    "    {'v2i_rate_{}'.format(benchmark) : v2i_rate_benchmark_list})\n",
    "scio.savemat(os.path.join(record_path, 'v2v_success_{}.mat'.format(benchmark)), \\\n",
    "    {'v2v_success_{}'.format(benchmark) : v2v_success_benchmark_list})"
   ]
  }
 ]
}